# -*- coding: utf-8 -*-
"""Kunal_appa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LoPAmrekXBQAnVC9DqTmKuG1MPeg8M7b

Hi Mam,

My name is Kunal Appa.I worked on Tobacco dataset.

Information about dataset : The tobaco.csv dataset can be used to analyze the demographic characteristics of smokers and types of tobacco consumed. It can also be used to explore the relationship between smoking and other factors.

The tobaco.csv dataset is a valuable resource for researchers and students who are interested in studying smoking behavior. It is also a useful dataset for data scientists who are interested in developing models to predict smoking behavior.
"""

# import lib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data
df = pd.read_csv("tobacco.csv")

"""The tobacco.csv dataset contains the prevalence and trends of tobacco use for 1995-2010. The data was collected by the Centers for Disease Control and Prevention (CDC) through the Behavioral Risk Factor Surveillance System (BRFSS). The BRFSS is a telephone survey that collects data on health-related behaviors and chronic diseases from adults in the United States.

The tobacco.csv dataset includes the following variables:

Year: The year of the survey.
State: The state in which the survey respondent resides.
Smoke everyday: The percentage of survey respondents who smoke cigarettes every day.
Smoke some days: The percentage of survey respondents who smoke cigarettes some days but not every day.
Former smoker: The percentage of survey respondents who used to smoke cigarettes but no longer do.
Never smoked: The percentage of survey respondents who have never smoked cigarettes.
Location 1: The latitude and longitude coordinates of the survey respondent's home.

"""

#print the first 9 rows
df.head(9)

#print the last 8 rows of the DataFrame
df.tail(8)

#it will print index dtype and column dtypes, non-null values and memory usage
df.info()

#it will drop the state columns
X = df.drop(columns=['Location 1'])
y = df['Location 1']

X

y

#it will print datatype
df.dtypes

#it will count the data in each column
df.count()

#it will print the null value in each column
print(df.isnull().sum())

# It calculates the following statistics for each column
df.describe()

# get the count of each unique value in the state colum
df['Year'].value_counts()

df['Never smoked'].value_counts().plot(kind="bar")

df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]

#creates a box plot of the Year
sns.boxplot(x=df["Year"])

# Visualize the dataset using pair plots or scatter matrix
sns.pairplot(df)
plt.show()

#, technique used to remove outliers from a dataset
Q1 =df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
data = df[~((df < (Q1 - 1.5 * IQR)) |(df> (Q3 + 1.5 * IQR))).any(axis=1)]

#  count plot of the variable Smoke everyday in the dataset data bar chart that shows the category of a categorical variable.
sns.countplot(x="Smoke everyday",data=data)

#plot the scatter plt from mat plot it data["Smoke everyday"] column contains the number of people who smoke every day, and the data["Smoke some days"]
plt.scatter(data["Smoke everyday"],data["Smoke some days"])

# it will print box plot in x realtion with former smoker and y with Year
sns.boxplot(x="Former smoker",y="Year",data=data)

#create heatmap graph plot
sns.heatmap(df.corr(), annot=True)
plt.show()

# Plot a histogram of the 'Price in INR' column with KDE (Kernel Density Estimation)
# Display the histogram
sns.histplot(df['Smoke everyday'], kde=True)
plt.show()

#selects all rows and all columns except the last column from the DataFrame and print table
x=df.iloc[::,:-1 ]
x.head()

y=data.iloc[:,-1]
y.head()

#calculates the skewness of the values
df.skew(axis = 0, skipna = True)

#technique that converts categorical data into numerical data#
le = LabelEncoder()

for column in df.columns:
    if df[column].dtype == "object":
        df[column] = le.fit_transform(df[column])

#imports the train_test_split function from the sklearn.model_selection module
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df, df["Smoke everyday"], test_size=0.3, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder

from sklearn.metrics import classification_report,confusion_matrix

#creates a new instance of the LogisticRegression
model = LogisticRegression()
#fits the model
model.fit(X_train,y_train)

#make a prediction using a trained model
ypred=model.predict(X_test)

#print classification report  on model
print(classification_report(y_test,ypred))

#accuracy of a model or datafarme
model.score(X_train,y_train)

x.head()

#predicate the table values add to function for logistic reg and predict
def new_prediction():
  Year=int(input('Enter year : '))
  State=int(input('Enter State : '))
  Smoke_everyday=int(input('Enter a  Smoke everyday	 : '))
  Smoke_some_days=int(input('Enter the Smoke some days: '))
  Former_smoker=int(input('Enter Former smoker	 : '))
  Never_smoked=int(input('Enter Never smoked: '))
  Never_smoked=int(input('Enter Never smoked: '))
  return ([[Year,State,Smoke_everyday,Smoke_some_days,Former_smoker,Never_smoked,Never_smoked]])

new_x=new_prediction()
pred=model.predict(new_x)
if pred==1:
  print('Smoker smokes everday')
else :
  print("Don't smokes never!!!")